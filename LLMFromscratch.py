
#https://www.kdnuggets.com/beginners-guide-to-building-llm-apps-with-python
# installing openai LLM
# pip install openai

#LangChain:LangChain is a framework designed to simplify the development of applications that leverage LLMs. It provides tools and utilities to manage and streamline the various aspects of working with LLMs, making building complex and robust applications easier.
#Install LangChain on your computer using the command below:

#pip install langchain


#Streamlit: Streamlit is a powerful and easy-to-use Python library for creating web applications. Streamlit allows you to create interactive web applications using Python alone. You don't need expertise in web development (HTML, CSS, JavaScript) to build functional and visually appealing web apps.
#It's beneficial for building machine learning and data science apps, including those that utilize LLMs. Install streamlit on your computer using the command below:

#pip install streamlit


# Importing the necessary modules from the Streamlit and LangChain packages
import streamlit as st
from langchain.llms import OpenAI

# Setting the title of the Streamlit application
print("setting title of the App")
st.title('Simple LLM-App ðŸ¤–')

# Creating a sidebar input widget for the OpenAI API key, input type is password for security
#OpenAI API Secret Key: sk-2Y8AJZY9JIUPrRXDBgmrAdsf4SJ_zUn_uRC_noPTnQT3BlbkFJMGjL46s5GBUMbnz73E9Q78tekZeLUA9JcV6M19YS0A
#New API Key: 
openai_api_key = st.sidebar.text_input('OpenAI API Key', type='password')


# Defining a function to generate a response using the OpenAI language model
def generate_response(input_text):
    # Initializing the OpenAI language model with a specified temperature and API key
    #Temperature is a parameter used to control the randomness or creativity of the text generated by a language model. It determines how much variability the model introduces into its predictions.

#Low Temperature (0.0 - 0.5): This makes the model more deterministic and focused.
#Medium Temperature (0.5 - 1.0): Provides a balance between randomness and determinism.
#High Temperature (1.0 and above): Increases the randomness of the output. Higher values make the model more creative and diverse in its responses, but this can also lead to less coherence and more nonsensical or off-topic outputs.
    llm = OpenAI(temperature=0.3, openai_api_key=openai_api_key)
    # Displaying the generated response as an informational message in the Streamlit app
    st.info(llm(input_text))

    # Creating a form in the Streamlit app for user input
with st.form('my_form'):
    # Adding a text area for user input
    text = st.text_area('Enter text:', '')
    # Adding a submit button for the form
    submitted = st.form_submit_button('Submit')
    # Displaying a warning if the entered API key does not start with 'sk-'
    if not openai_api_key.startswith('sk-'):
        st.warning('Please enter your OpenAI API key!', icon='âš ')
    # If the form is submitted and the API key is valid, generate a response
    if submitted and openai_api_key.startswith('sk-'):
        generate_response(text)

        #Running the application: The application is ready; you need to execute the application script using the appropriate command for the framework you're using.

#streamlit run llmfromscratch.py
#When you execute streamlit run app.py, the following happens:

#Streamlit server starts: Streamlit starts a local web server on your machine, typically accessible at `http://localhost:8501` by default.
#Code execution: Streamlit reads and executes the code in `app.py,` rendering the app as defined in the script.
#Web interface: Your web browser automatically opens (or you can manually navigate) to the URL provided by Streamlit (usually http://localhost:8501), where you can interact with your LLM app.